{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Notebook order\n",
    "\n",
    "This notebook is the 1st notebook in milestone 1. \n",
    "\n",
    "In this notebook, we explore and decide what to do in the data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://raw.githubusercontent.com/MohamedMostafa259/Customer-Churn-Prediction-and-Analysis/main/Data/train.csv\")\n",
    "train_copy = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "- What does `'xxxxxxxx'` mean in the `'referral_id'` column?\n",
    "\n",
    "- The `'avg_frequency_login_days'` numeric column seems to contain values = `'Error'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.isna().sum()[train_copy.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "- These columns contain NaNs:\n",
    "\n",
    "\t-\tregion_category               \n",
    "\t-\tpreferred_offer_types         \n",
    "\t-\tpoints_in_wallet              \n",
    "\n",
    "- The `'avg_frequency_login_days'` numeric column has type of `object`! (from previous comments cell, we found out that it seems to contain values = `'Error'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['churn_risk_score'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.describe(include=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "`gender` column has 3 unique categories!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['gender'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.loc[train_copy['days_since_last_login'] < 0, 'days_since_last_login'] = np.nan\n",
    "train_copy.loc[train_copy['avg_time_spent'] < 0, 'avg_time_spent'] = np.nan\n",
    "train_copy.loc[train_copy['points_in_wallet'] < 0, 'points_in_wallet'] = np.nan\n",
    "\n",
    "train_copy.loc[train_copy['churn_risk_score'] == -1, 'churn_risk_score'] = np.nan\n",
    "train_copy.dropna(subset=['churn_risk_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "- Negative values should be set to `np.nan` in these columns:\n",
    "\n",
    "\t-\tdays_since_last_login\n",
    "\t-\tavg_time_spent\n",
    "\t-\tpoints_in_wallet\n",
    "\t-\tchurn_risk_score (NaNs in the target: these rows needs to be dropped)\n",
    "\n",
    "-\tTarget class has imbalanced class distribution\n",
    "\n",
    "- `'gender'` column contains a category called `'Unknown'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Category value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_copy.select_dtypes(include='object').columns:\n",
    "\tprint(train_copy[col].value_counts(normalize=True, dropna=False))\n",
    "\tprint('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.loc[train_copy['avg_frequency_login_days'] == 'Error', 'avg_frequency_login_days'] = np.nan\n",
    "train_copy['avg_frequency_login_days'] = train_copy['avg_frequency_login_days'].astype(float)\n",
    "train_copy.loc[train_copy['avg_frequency_login_days'] < 0, 'avg_frequency_login_days'] = np.nan\n",
    "train_copy['avg_frequency_login_days'].value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "-\tAround $14\\%$ of `'joined_through_referral'` and `'medium_of_operation'` columns = `'?'`\n",
    "-\tcols_to_drop ↓↓\n",
    "\n",
    "\t-\tWe need to drop unnecessary columns: `train.drop(columns=cols_to_drop, inplace=True)`\n",
    "\n",
    "-\tdate_cols ↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['customer_id', 'Name', 'security_no', 'referral_id']\n",
    "\n",
    "# date_cols = [('date', 'date_format'), ...]\n",
    "date_cols = [('joining_date', '%Y-%m-%d'), ('last_visit_time', '%H:%M:%S')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.duplicated(['customer_id']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Visualizing distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.hist(bins=50, figsize=(10, 7))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 7, figsize=(18, 4))\n",
    "idx = 0\n",
    "for col in train_copy.select_dtypes(include=np.number).columns:\n",
    "\tsns.kdeplot(train_copy[col], ax=axes[idx])\n",
    "\tidx += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 7, figsize=(18, 4))\n",
    "idx = 0\n",
    "for col in train_copy.select_dtypes(include=np.number).columns:\n",
    "\tsns.boxplot(train_copy[col], ax=axes[idx])\n",
    "\tidx += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_with_outliers = ['avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days', 'points_in_wallet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "sns.violinplot(train_copy['avg_time_spent'], ax=axes[0])\n",
    "# log1p(x) = log(x + 1): this avoids errors when x = 0\n",
    "sns.violinplot(np.log1p(train_copy['avg_time_spent']), ax=axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "Some columns have non-normal and non-uniform distributions. Also, they have outliers; however, I will not cap these outliers because they may introduce an important pattern in the data, for example, if `avg_transaction_value` has some very high values due to VIP customers, capping them may remove valuable patterns.\n",
    "\n",
    "So, I will apply log transformation to `avg_time_spent` to make it look more normal as it's right-skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Missing value analysis\n",
    "\n",
    "Before imputing NaNs, we need to have a good understanding of how they are distributed in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent = train_copy.isna().mean() * 100  \n",
    "missing_count = train_copy.isna().sum()           \n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "bars = plt.bar(missing_percent.index, missing_percent, color='skyblue')\n",
    "\n",
    "# Annotate bars with both count and percentage\n",
    "for bar, count, percent in zip(bars, missing_count, missing_percent):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "             f'{int(count)}\\n({percent:.1f}%)',\n",
    "             ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Missing Value Percentage')\n",
    "plt.title('Missing Data: Count and Percentage per Column')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['last_visit_time'] = pd.to_datetime(train_copy['last_visit_time'])\n",
    "train_copy.sort_values('last_visit_time', inplace=True)\n",
    "msno.matrix(train_copy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['joining_date'] = pd.to_datetime(train_copy['joining_date'])\n",
    "train_copy.sort_values('joining_date', inplace=True)\n",
    "msno.matrix(train_copy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(train_copy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "It's clear that there is no patterns in missingness (if some columns are missing together)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "\n",
    "`referral_id` should be populated only when `joined_through_referral` is \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['referral_id'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_rows = (train_copy['referral_id'] != 'xxxxxxxx') & (train_copy['joined_through_referral'] == 'No')\n",
    "train_copy.loc[wrong_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_rows = (train_copy['referral_id'] == 'xxxxxxxx') & (train_copy['joined_through_referral'] == 'Yes')\n",
    "train_copy.loc[wrong_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.loc[wrong_rows].hist(bins=50, figsize=(10, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.loc[wrong_rows].describe(include=object)\n",
    "# about 50% of them have 'complaint_status'='Not Applicable'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "There're lots of columns seems to have inconsistent data; how to deal with them?!\n",
    "\n",
    "I prefer to not remove them because first we need to ask the data owners what it means when 'referral_id' is equal to 'xxxxxxxx'. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
