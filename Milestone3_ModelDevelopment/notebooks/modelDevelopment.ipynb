{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verstack requirements.txt file:\n",
    "\n",
    "# !pip install \\\n",
    "#     \"numpy>=1.26.4,<=2.1.1\" \\\n",
    "#     \"pandas==2.2.2\" \\\n",
    "#     \"scikit-learn>=1.3.2,<=1.5.1\" \\\n",
    "#     \"lightgbm>=4.4.0,<=4.5.0\" \\\n",
    "#     \"optuna>=3.5.0,<=4.0.0\" \\\n",
    "#     \"optuna-integration>=3.2.0,<=4.0.0\" \\\n",
    "#     \"plotly>=5.11.0,<=5.24.0\" \\\n",
    "#     \"matplotlib==3.9.2\" \\\n",
    "#     \"seaborn==0.13.2\" \\\n",
    "#     \"python-dateutil==2.9.0\" \\\n",
    "#     \"holidays==0.56\" \\\n",
    "#     \"mlxtend==0.23.1\" \\\n",
    "#     \"category_encoders>=2.5.1,<=2.6.3\" \\\n",
    "#     \"verstack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression # Baseline\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC \n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "from verstack import NaNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Load preprocessed data (ready for modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed = pd.read_csv('https://raw.githubusercontent.com/MohamedMostafa259/Customer-Churn-Prediction-and-Analysis/refs/heads/main/Milestone2_FeatureEng_AdvancedAnalysis/data/train_split_preprocessed.csv')\n",
    "train_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = train_preprocessed.drop('churn_risk_score', axis=1)\n",
    "y_train = train_preprocessed['churn_risk_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Selecting promising models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0),\n",
    "    'LightGBM': LGBMClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"CV on {name}\")\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X_train_preprocessed,\n",
    "# target labels (y_train_split) starts from '1': [1, 2, 3, 4, 5], \n",
    "# but XGBoost expects them to start from 0, like [0, 1, 2, 3, 4].\n",
    "        y_train - 1,\n",
    "# don't forget to add one in the prediction time:\n",
    "# y_pred = xgb_clf.predict(X_test_preprocessed) + 1\n",
    "        cv=4,\n",
    "        scoring='accuracy',\n",
    "        return_train_score=True\n",
    "    )\n",
    "    print(f\"Train Accuracy: {cv_results['train_score'].mean():.4f} (+/- {cv_results['train_score'].std():.4f})\")\n",
    "    print(f\"Validation Accuracy: {cv_results['test_score'].mean():.4f} (+/- {cv_results['test_score'].std():.4f})\")\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "It's clear that XGBoost, CatBoost, LightGBM are the best models. So, we will take them to next step, which hyperparamater tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "\t('model', LogisticRegression()) # will be replaced by the best model\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [XGBClassifier(verbosity=0, random_state=42)],\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.01, 0.1],\n",
    "        'model__max_depth': [6, 10, 13],\n",
    "        'model__subsample': [0.5, 0.75, 1],\n",
    "    },\n",
    "    {\n",
    "        # `bootstrap_type='Bernoulli'` is required for `subsample` parameter to work\n",
    "        'model': [CatBoostClassifier(verbose=0, random_state=42, bootstrap_type='Bernoulli')],\n",
    "        'model__iterations': [100, 200],  # CatBoost uses iterations instead of n_estimators\n",
    "        'model__learning_rate': [0.01, 0.1],\n",
    "        'model__depth': [6, 10, 13],  # CatBoost uses depth instead of max_depth\n",
    "        'model__subsample': [0.5, 0.75, 1],\n",
    "    },\n",
    "    {\n",
    "        'model': [LGBMClassifier(verbose=-1, random_state=42)],\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.01, 0.1],\n",
    "        'model__max_depth': [6, 10, 13],\n",
    "        'model__subsample': [0.5, 0.75, 1],\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = RandomizedSearchCV(pipe, param_distributions=param_grid, cv=4, scoring='accuracy', \n",
    "                    verbose=1, return_train_score=True, n_iter=60, n_jobs=-1, \n",
    "                    error_score='raise', random_state=42)\n",
    "\n",
    "grid.fit(X_train_preprocessed, y_train-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(grid.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "print(cv_results_df.shape)\n",
    "cols_to_show = [ \"rank_test_score\", \"mean_test_score\", \"std_test_score\",\n",
    "                \"mean_train_score\", \"std_train_score\", \"param_model\", \n",
    "                \"param_model__subsample\", \"param_model__n_estimators\",\n",
    "                \"param_model__max_depth\", \"param_model__learning_rate\"\n",
    "]\n",
    "cv_results_df[cols_to_show].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df[(cv_results_df['param_model__subsample']==0.750) & (cv_results_df['param_model__n_estimators']==100) &\\\n",
    "                (cv_results_df['param_model__max_depth']==6) & (cv_results_df['param_model__learning_rate']==0.01)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The best model was `XGBClassifier` with these parameters:\n",
    "- 'subsample': 0.75,\n",
    "- 'n_estimators': 200,\n",
    "- 'max_depth': 6,\n",
    "- 'learning_rate': 0.01\n",
    "\n",
    "Let's see what is the performance of the same model with 'n_estimators'=100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(verbosity=0, random_state=42, n_estimators=100, \n",
    "                       learning_rate=0.01, max_depth=6, subsample=0.75)\n",
    "xgb_cv_results = cross_validate(xgb_clf, X_train_preprocessed, y_train-1, \n",
    "                                cv=4, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"XGB Train Accuracy: {xgb_cv_results['train_score'].mean():.4f} (+/- {cv_results['train_score'].std():.4f})\")\n",
    "print(f\"XGB Validation Accuracy: {xgb_cv_results['test_score'].mean():.4f} (+/- {cv_results['test_score'].std():.4f})\")\n",
    "print('\\nBest model from cross validation:')\n",
    "cv_results_df[['mean_train_score', 'mean_test_score']].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "It seems that the best model XGBClassifier, resulted from the Randomized Cross Validation above, performs better (or equivalent) when having less number of estimators: n_estimators=100 !!\n",
    "\n",
    "So, let's stick with this simpler version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Merging the selected ml model with the previous pipelines & transformers into one pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `DataCleaner` and `NaNImputerWrapper` are needed for `cleaning_pipeline`\n",
    "from custom_transformers import DataCleaner, NaNImputerWrapper, FeatureEng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_cleaned = pd.read_csv('https://raw.githubusercontent.com/MohamedMostafa259/Customer-Churn-Prediction-and-Analysis/main/Milestone1_DataCollection_EDA_DataCleaning/data/train_split_cleaned.csv')\n",
    "val_split_cleaned = pd.read_csv('https://raw.githubusercontent.com/MohamedMostafa259/Customer-Churn-Prediction-and-Analysis/main/Milestone1_DataCollection_EDA_DataCleaning/data/validation_split_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split = train_split_cleaned.drop('churn_risk_score', axis=1)\n",
    "y_train_split = train_split_cleaned['churn_risk_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_split = val_split_cleaned.drop('churn_risk_score', axis=1)\n",
    "y_val_split = val_split_cleaned['churn_risk_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ../ means go up one dir\n",
    "cleaning_pipeline = joblib.load(\"../../Milestone1_DataCollection_EDA_DataCleaning/pipelines/cleaning_pipeline.joblib\")\n",
    "cleaning_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cleaning_pipeline', cleaning_pipeline),  \n",
    "    ('feature_engineering', FeatureEng()), \n",
    "\t('model', xgb_clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_split, y_train_split-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = pipeline.predict(X_train_split) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_accuracy:', accuracy_score(y_train_split, y_train_pred), '\\n')\n",
    "print('train_classification_report:\\n', classification_report(y_train_split, y_train_pred), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = pipeline.predict(X_val_split) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_accuracy:', accuracy_score(y_val_split, y_val_pred), '\\n')\n",
    "print('test_classification_report:\\n', classification_report(y_val_split, y_val_pred), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Summary of the model results\n",
    "\n",
    "* **Overall test accuracy**: **0.788** → The model correctly predicts the class **\\~79% of the time** across the entire test set, which is better than the score of the 1st winner of the competition made on this dataset! [He built a model with **77%** accuracy.](https://www.hackerearth.com/challenges/new/competitive/hackerearth-machine-learning-challenge-predict-customer-churn/#:~:text=Machine%20Learning%20practice-,Winners,-Adarsh%20Wase)\n",
    "\n",
    "* **F1-score (macro avg) = F1-score (weighted avg) = 0.77** → The model performs well overall despite imbalanced data.\n",
    "\n",
    "---\n",
    "\n",
    "**One Limitation of the model:**\n",
    "\n",
    "It has low recall (0.43) on class 4, leading to a low f1-score (0.57) on that class as well. \n",
    "\n",
    "As a result, many real class 4s are getting misclassified. \n",
    "\n",
    "**Solution** may be:\n",
    "\n",
    "* More examples \n",
    "\n",
    "* Better features focusing on separating class 4\n",
    "\n",
    "* decreasing the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Saving the final ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipeline, '/kaggle/working/full_xgb_pipeline.joblib')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7371309,
     "sourceId": 11742428,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "sourceId": 408540,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
